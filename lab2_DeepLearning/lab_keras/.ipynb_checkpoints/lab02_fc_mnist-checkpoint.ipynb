{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 全相连网络(Full Connected Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#!/usr/bin/env python\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: x = (60000, 28, 28) , y = (60000,)\n",
      "测试集大小: x = (10000, 28, 28) , y = (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('训练集大小: x =', x_train.shape, ', y =', y_train.shape)\n",
    "print('测试集大小: x =', x_test.shape, ', y =', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F40665403D0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.fromarray(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape/flatten: image from 2D (28*28) to 1D (784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: x = (60000, 784) , y = (60000, 10)\n",
      "test data: x = (10000, 784) , y = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# hyper-parameter\n",
    "training_epoch=100\n",
    "num_classes = 10\n",
    "learning_rate=1e-3\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype('float32') / 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('training data: x =', x_train.shape, ', y =', y_train.shape)\n",
    "print('test data: x =', x_test.shape, ', y =', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_size = x_train.shape[-1]\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(image_size,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import *\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训连 training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.fit`函数接口\n",
    "```\n",
    "fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,\n",
    "            validation_split=0., validation_data=None, shuffle=True,\n",
    "            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs)\n",
    "```\n",
    "其中`x,y`表示全部数据集；callbacks是高级借口（后面会讲）；`verbose`为1表示输出每一次batch的训练结果，为0表示不做任何输出；`validation_split`在0~1，是将训练集按照一定比例划分为验证集；`validation_data`是验证集，训练时加入验证集有助有模型的训练过程，会使得模型着重学习验证集，可能会导致模型性能突发提升；`initial_epoch`是模型的出事训练周期数，这对于一些自适应优化器和加载模型参数非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2907 - acc: 0.9110 - val_loss: 0.1145 - val_acc: 0.9637\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1178 - acc: 0.9652 - val_loss: 0.0883 - val_acc: 0.9726\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0868 - acc: 0.9734 - val_loss: 0.0725 - val_acc: 0.9771\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0675 - acc: 0.9802 - val_loss: 0.0728 - val_acc: 0.9782\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0599 - acc: 0.9821 - val_loss: 0.0706 - val_acc: 0.9797\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0497 - acc: 0.9846 - val_loss: 0.0735 - val_acc: 0.9788\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0456 - acc: 0.9856 - val_loss: 0.0613 - val_acc: 0.9817\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0399 - acc: 0.9872 - val_loss: 0.0665 - val_acc: 0.9817\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0391 - acc: 0.9882 - val_loss: 0.0800 - val_acc: 0.9763\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0659 - val_acc: 0.9829\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0638 - val_acc: 0.9826\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0308 - acc: 0.9905 - val_loss: 0.0772 - val_acc: 0.9804\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0649 - val_acc: 0.9831\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0257 - acc: 0.9918 - val_loss: 0.0691 - val_acc: 0.9822\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0686 - val_acc: 0.9841\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0814 - val_acc: 0.9818\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 0.0714 - val_acc: 0.9839\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0685 - val_acc: 0.9847\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0637 - val_acc: 0.9843\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0743 - val_acc: 0.9830\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0193 - acc: 0.9942 - val_loss: 0.0715 - val_acc: 0.9845\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0181 - acc: 0.9939 - val_loss: 0.0813 - val_acc: 0.9835\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0181 - acc: 0.9947 - val_loss: 0.0860 - val_acc: 0.9817\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.0771 - val_acc: 0.9829\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0749 - val_acc: 0.9848\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0156 - acc: 0.9952 - val_loss: 0.0766 - val_acc: 0.9851\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0780 - val_acc: 0.9842\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0681 - val_acc: 0.9845\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0901 - val_acc: 0.9816\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0763 - val_acc: 0.9847\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0731 - val_acc: 0.9843\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0152 - acc: 0.9955 - val_loss: 0.0796 - val_acc: 0.9845\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0140 - acc: 0.9960 - val_loss: 0.0828 - val_acc: 0.9852\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0745 - val_acc: 0.9843\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0848 - val_acc: 0.9829\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0958 - val_acc: 0.9821\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 0.0846 - val_acc: 0.9851\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0761 - val_acc: 0.9854\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0878 - val_acc: 0.9833\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0803 - val_acc: 0.9853\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0966 - val_acc: 0.9830\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0920 - val_acc: 0.9832\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0872 - val_acc: 0.9844\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0942 - val_acc: 0.9841\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0900 - val_acc: 0.9851\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0154 - acc: 0.9959 - val_loss: 0.0869 - val_acc: 0.9841\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0979 - val_acc: 0.9826\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0851 - val_acc: 0.9850\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0953 - val_acc: 0.9847\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0102 - acc: 0.9970 - val_loss: 0.0935 - val_acc: 0.9844\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0906 - val_acc: 0.9838\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.0992 - val_acc: 0.9834\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0962 - val_acc: 0.9832\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0871 - val_acc: 0.9849\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0900 - val_acc: 0.9850\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0929 - val_acc: 0.9840\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0901 - val_acc: 0.9838\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.0988 - val_acc: 0.9852\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.1029 - val_acc: 0.9829\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.1021 - val_acc: 0.9833\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0870 - val_acc: 0.9852\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.0941 - val_acc: 0.9848\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0907 - val_acc: 0.9857\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0906 - val_acc: 0.9845\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0108 - acc: 0.9969 - val_loss: 0.0855 - val_acc: 0.9833\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.1043 - val_acc: 0.9839\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0960 - val_acc: 0.9851\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0110 - acc: 0.9973 - val_loss: 0.0978 - val_acc: 0.9845\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0814 - val_acc: 0.9851\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0862 - val_acc: 0.9860\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0846 - val_acc: 0.9849\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.0910 - val_acc: 0.9866\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0987 - val_acc: 0.9845\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.0846 - val_acc: 0.9858\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0845 - val_acc: 0.9857\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0914 - val_acc: 0.9851\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0949 - val_acc: 0.9865\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.0941 - val_acc: 0.9851\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.1077 - val_acc: 0.9850\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0111 - acc: 0.9970 - val_loss: 0.1078 - val_acc: 0.9847\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0952 - val_acc: 0.9858\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0932 - val_acc: 0.9850\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0106 - acc: 0.9972 - val_loss: 0.0985 - val_acc: 0.9842\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0936 - val_acc: 0.9854\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0952 - val_acc: 0.9846\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.1021 - val_acc: 0.9850\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0968 - val_acc: 0.9860\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0934 - val_acc: 0.9858\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0962 - val_acc: 0.9851\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.1062 - val_acc: 0.9851\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0894 - val_acc: 0.9866\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0948 - val_acc: 0.9854\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0893 - val_acc: 0.9852\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0974 - val_acc: 0.9852\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.1050 - val_acc: 0.9845\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.1118 - val_acc: 0.9841\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0935 - val_acc: 0.9855\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0992 - val_acc: 0.9843\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0988 - val_acc: 0.9850\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.1041 - val_acc: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f402f7caf10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=100,\n",
    "          epochs=training_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检验 estimaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.10411224436, test accuracy: 0.9851\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss: %s, test accuracy: %s' % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAAAAAAH9lwLAAAAa0lEQVR4nO2UQQ7AIAgEtf//s15p\ns8vQGpMe5GZkHEjA1k78KHo8jBEu+jO1CMrkkH3VCgMjuaMROrk/87JUhS30iKD27TM6X9GopigF\ns0lKQF9mCtLcYo9uSwxIPjT6rZQg+3ZNDn0fn2IC6zAYJYGcViEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=I size=28x28 at 0x7F4063867110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = x_test[0]\n",
    "Image.fromarray(test.reshape(28, 28), 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = test[None, :]\n",
    "# 模型预测\n",
    "x_predicted = model.predict(test)\n",
    "np.argmax(x_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

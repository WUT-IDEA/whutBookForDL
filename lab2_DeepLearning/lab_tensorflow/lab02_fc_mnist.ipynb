{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 全相连网络(Full Connected Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入MNIST数据集<br>\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/)(读作minist)，是由LeCunn等三位大佬在98年贡献的手写数字数据集。<br>\n",
    "每张图片为28*28像素的二值图，算得上是深度学习的入门资料。地位如同helloworld程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "训练集大小: 55000;\n",
      "验证集大小: 5000;\n",
      "测试集大小: 10000.\n",
      "输入的大小：784\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)\n",
    "print(\n",
    "    '训练集大小: %s;\\n验证集大小: %s;\\n测试集大小: %s.' % \\\n",
    "    (mnist.train.num_examples, mnist.validation.num_examples, mnist.test.num_examples)\n",
    ")\n",
    "image_size = mnist.train.images[0].shape[0]\n",
    "print('输入的大小：%s' % (image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAAAAAAH9lwLAAAAeElEQVR4nO2SOw7AMAhDSZT7Xznd\nWgE2OEOlDvUY+RHzMfv1IQ38vPdtII4RjcSW8KlgyDE7hKGrilOlIa0j1BeWo0a14BPVh17Zmk1I\nAOwhAGpQAiM2iruCPfrB43UkkB11+aMKmR3sMRZ963LYfw3IMSnqycgEXYkPJCx6Icq0AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=I size=28x28 at 0x7F75D066B510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "Image.fromarray(np.reshape(a=mnist.train.images[0], newshape=(28, 28)), 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 超参数(hyper-parameter)是指构成网络的参数，迭代次数/batch大小也可以作为超参数的一部分\n",
    "training_epoch = 100\n",
    "num_class = 10\n",
    "learning_rate=1e-3\n",
    "batch_size=100\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('placehold'):\n",
    "        # placehold - define variable\n",
    "        x = tf.placeholder(dtype=tf.float32, shape=[None, image_size], name='x')\n",
    "        y = tf.placeholder(dtype=tf.float32, shape=[None, num_class], name='y')\n",
    "\n",
    "\n",
    "    def linear(input_data, name=None, target=None, activation=tf.nn.relu):\n",
    "        original = int(list(input_data.shape)[-1])\n",
    "        with tf.name_scope('layer_%s' % (name)):\n",
    "            # define two variable for y=a*x+b\n",
    "            weight_a = tf.Variable(tf.random_normal(shape=[original, target], mean=.0, stddev=.1),\n",
    "                                   name='layer_%s_a' % (name))\n",
    "            weight_b = tf.Variable(tf.zeros(shape=[target]), name='layer_%s_b' % (name))\n",
    "        return activation(tf.matmul(input_data, weight_a) + weight_b)\n",
    "\n",
    "\n",
    "    # MLP\n",
    "    fc1 = linear(input_data=x, name='1', target=256)\n",
    "    # dropout是神经网络中重要的提示网络性能的手段。它不是网络。\n",
    "    # dropout可以放置过拟合，提升网络准确率，得到数据特征等作用。\n",
    "    # 类似的还有batchnorm等，都对网络性能的提升有着关键性的作用\n",
    "    fc1 = tf.layers.dropout(inputs=fc1, rate=0.7)\n",
    "    fc2 = linear(input_data=fc1, name='2', target=64)\n",
    "    fc3 = linear(input_data=fc2, name='3', target=num_class, activation=tf.nn.softmax)\n",
    "    y_ = fc3\n",
    "\n",
    "    with tf.name_scope('loss_op'):\n",
    "        loss_op = tf.losses.mean_squared_error(y, y_)\n",
    "    with tf.name_scope('train_op'):\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "    with tf.name_scope('accuracy_op'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch不宜太大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 100, loss: 0.00350002, accuracy: 0.9772\n",
      "Epoch 20 / 100, loss: 0.0031719, accuracy: 0.9794\n",
      "Epoch 30 / 100, loss: 0.00422966, accuracy: 0.9745\n",
      "Epoch 40 / 100, loss: 0.00366471, accuracy: 0.9779\n",
      "Epoch 50 / 100, loss: 0.00421658, accuracy: 0.9758\n",
      "Epoch 60 / 100, loss: 0.00370491, accuracy: 0.9787\n",
      "Epoch 70 / 100, loss: 0.00321772, accuracy: 0.9827\n",
      "Epoch 80 / 100, loss: 0.00346821, accuracy: 0.9806\n",
      "Epoch 90 / 100, loss: 0.00374925, accuracy: 0.9792\n",
      "Epoch 100 / 100, loss: 0.00374149, accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    batch_episode=len(mnist.train.images)//batch_size\n",
    "    for i in xrange(1, 1 + training_epoch):\n",
    "        for _ in xrange(batch_episode):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            feed = {x: batch_x, y: batch_y}\n",
    "            _, batch_cost, batch_acc = session.run([train_op, loss_op, accuracy], feed_dict=feed)\n",
    "        if i % 10 == 0:\n",
    "            loss_val, acc_val = session.run([loss_op, accuracy], feed_dict={\n",
    "                x: mnist.test.images,\n",
    "                y: mnist.test.labels\n",
    "            })\n",
    "            print('Epoch %s / %s, loss: %s, accuracy: %s' % (i, training_epoch, loss_val, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检验\n",
    "estimaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAAAAAAH9lwLAAAAa0lEQVR4nO2UQQ7AIAgEtf//s15p\ns8vQGpMe5GZkHEjA1k78KHo8jBEu+jO1CMrkkH3VCgMjuaMROrk/87JUhS30iKD27TM6X9GopigF\ns0lKQF9mCtLcYo9uSwxIPjT6rZQg+3ZNDn0fn2IC6zAYJYGcViEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=I size=28x28 at 0x7F7594741E50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在深度学习中实际值/真实值叫做ground truth\n",
    "Image.fromarray(np.reshape(a=mnist.test.images[0], newshape=(28, 28)), 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted image is 8\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    predict = session.run([y_], feed_dict={\n",
    "        x: mnist.test.images[0][None, ...],\n",
    "        y: mnist.test.labels[0][None, ...]\n",
    "    })\n",
    "    # prediction\n",
    "    print('predicted image is %s' % (np.argmax(a=predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐资料：<br>\n",
    "[Stanford UFLDL课程，神经网络](http://deeplearning.stanford.edu/wiki/index.php/Neural_Networks)<br>\n",
    "[Stanford UFLDL课程，backprogation算法](http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm)<br>\n",
    "[Stanford UFLDL课程，backprogation算法](http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm)<br>\n",
    "[Stanford UFLDL课程，梯度检验与高级优化](http://deeplearning.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization)<br>\n",
    "[Micheal Nielsen, *Neural Networks and Deep Learning*](http://neuralnetworksanddeeplearning.com/index.html)<br>\n",
    "[sklearn库，神经网络](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)<br>\n",
    "[TensorFLow全相连网络实现MNIST识别（教程代码的版本太低）](http://www.tensorfly.cn/tfdoc/tutorials/mnist_beginners.html)<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
